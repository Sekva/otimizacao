%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Relatório Final - Projeto de Pesquisa
% Métodos de Otimização
% Baltz & Machado
% Capítulo 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% TODO: usar aspas duplas

\chapter{\Large{Métodos Clássicos de Otimização}}\label{chp:2}


\section{{O Método de Newton}}

% TODO: Adicionar texto entre o início do cap e início da sessao
% Talvez falar sobre newton, sobre a criação do método, e tals
% Fazer a introdução

\subsection{Entendendo o Método}

\hspace{0.8cm}
O Método de Newton, foi desenvolvido com o objetivo de encontrar estimativas
para as raízes de uma função. De modo que, a execução do método é feita de
forma iterativa, repetindo sempre o mesmo processo, atualizando o mesmo valor.

Este método faz uso do recurso de derivação. Existindo uma relação muito
forte com o ângulo da reta tangente à curva, que é o gráfico da função que
foi derivada. Ademais, é importante ressaltar a necessidade de um "palpite"
inicial, que represente o valor de \textit{x}, para o qual será buscado uma
estimativa da raiz. E com isso vamos entender como o método funciona.

O método em princípio consiste na utilização da reta tangente à um
ponto sobre à curva, para gerar valores cada vez mais próximos da raiz
daquela função. Analisamos a interseção da reta tangente com o eixo das
abscissas. Obtendo o ponto P1($x_p$, $y_p$). O novo valor de entrada na função
será construído com base nas coordenadas desse ponto.

A equação da reta que passa por um ponto de coordenada ($x_0$, $y_0$) é dada
por:

\begin{equation}
    (y - y_0) = m(x - x_0).
\end{equation}

E levando em conta que temos como objetivo encontrar $x$, que é um ponto
sobreposto no eixo x, podemos considerar $y=0$. Logo:

\begin{equation}
    -y_0=m(x-x_0).
\end{equation}

Com isso sabemos que $y_0$ é a imagem da função $f(x_0)$, e $m$ representa o
ângulo da reta tangente ao ponto ($x_0$, $y_0$). Como vimos no Capítulo 1,
 $m=f'(x_0)$. Desenvolvendo essa equação, temos:

\begin{equation}
    -f(x_0) = f'(x_0)(x-x_0),
\end{equation}

\begin{equation}
    -f(x_0) = f'(x_0)x - f'(x_0)x_0,
\end{equation}

\begin{equation}
    0 = f'(x_0)x - f'(x_0)x_0+f(x_0),
\end{equation}

\begin{equation}
    0 = x - x_0 + \frac{f(x_0)}{f'(x_0)},
\end{equation}

\begin{equation}
    x = x_0 - \frac {f(x_0)}{f'(x_0)}.
\end{equation}\\

Exemplificaremos no gráfico a seguir. Considerando a função $f(x)=-x^2+2x$, e
que o palpite inicial é $x_0=1.5$. $P1$ representa o ponto quando aplicamos
$x_0$ a $f(x)$. Podemos observar que como fruto da intersecção da reta tangente em azul
encontramos o valor $x_1$ que será usado na próxima iteração.

\begin{figure}[ht]
    \includegraphics[width=0.55\textwidth]
      {src/MetodoNewton_grafico_1.png}
    \centering
    \caption{
      Primeira iteração do Método de Newton.
     }
    \label{MetodoNewton_grafico_1}
\end{figure}


Agora podemos entender melhor como a iteração funcionará. O valor
gerado, $x_1$, será aplicado no mesmo procedimento. E, a partir disso,
poderemos construir as seguintes equações:

\begin{equation}
    x_{1} = x_{0} - \frac {f(x_{0})}{f'(x_{0})},
\end{equation}

\begin{equation}
    x_{k+1} = x_{k} - \frac {f(x_{k})}{f'(x_{k})}.
    \label{newton_primeiraDeriv}
\end{equation}

% TODO: Provar o Teorema de Convergência do Método de Newton, escrever o
%teorema lá no final (do tópico ou do capítulo)

Desse modo, gera-se uma sequência $\{x_k\}$, que deve convergir para a
raiz da função (este é o cerne do Teorema de Convergência do Método de Newton).
Reconsiderando a função $f(x)$ do exemplo mostrado na Figura
\ref{MetodoNewton_grafico_1}, encontramos a pŕoxima iteração que apresentamos
na Figura \ref{MetodoNewton_grafico_2}:

\begin{figure}[h]
    \centering
    \includegraphics[width=0.55\textwidth]
      {src/MetodoNewton_grafico_2.png}
    \caption{
      Segunda iteração do Método de Newton.
    }
    \label{MetodoNewton_grafico_2}
\end{figure}

\newpage
Podemos notar que $x_2$ é um ponto mais próximo da raiz $f(x)$ do que $x_1$
ou $x_0$. O que evidencia a provável convergência da sequência $x_k$ para a
raiz.

É válido ressaltar que o denominador da equação
\ref{newton_primeiraDeriv} tem que ser diferente de 0 (ou seja, a reta tangante
num ponto $P$ não pode ser paralela ao eixo x). Caso contrário, teríamos
que a dada função não possui raiz na proximidade daquele ponto. Ademais, o
palpite, denotado por $x_0$, deve ser suficientemente próximo das raizes, para
garantir cerelidade da convergência.

Para aprimorar os resultados expostos, descrevemo-los como no seguinte teorema:

aloo
% TODO: Escrever aqui o teorema de Newton e a demonstração


\subsection{Encontrando Mínimos}

% TODO: Arruamar esse paragrafo

\hspace{0.8cm}
Agora podemos utilizar este método para encontrar mínimos de uma função.
O Método de Newton calcula raízes. É possível vincular isto, com o que
foi estudado no Capítulo 1. Obtemos os mínimos de uma função que como vimos
podem ser representados como raízes de sua derivada. Considerando $g(x)$ uma
função duas vezes diferenciável, e tendo como objetivo encontrar seus pontos
de mínimo, pode-se utilizar o Método de Newton para resolver tal problema o
que gera a seguinte sequência:

%TODO: Falar mais/melhor sobre a sequencia {x_k} (tendencia ao 0 da função)

\begin{equation}
    x_{k+1} = x_{k} - \frac {g'(x_{k})}{g''(x_{k})}.
    \label{convergencia_segundaDeriva}
\end{equation}

A convergência da sequência \ref{convergencia_segundaDeriva}, é um valor $x^*$
que satisfaz a equação:

\begin{equation}
    g'(x^*) = 0.
\end{equation}

O método é simples, entrega muitas vezes ótimos locais próximos ao ponto
inicial, mas tem seu destaque, que é ser, facilmente computável.

Problemas de maximização podem ser vistos sob o seguinte olhar:

\begin{equation}
    max(f(x)) = min(-1 * f(x)).
\end{equation}

O que faz com que o Método de Newton possa ser utilizado em ambos sentidos no
processo de otimizar.

O movimento de \(x_k\) dentro da sequência, é determinado pela relação das
quantidades e propriedades, que tanto a primeira quanto a segunda derivada
oferecem. As quantidades, determinam a velocidade do movimento, e os sinais,
indicam a direção do movimento. De certa forma, podemos interpretar o movimento
da sequência \(\{x_k\}\) como instantes do movimento de uma bola numa ladeira,
que no começo de sua descida é acelerada, e, conforme chega ao plano no fim da
ladeira, começa a reduzir sua velocidade, até supostamente chegar no ponto mais
baixo.


\section{{Outros Métodos}}

\hspace{0.8cm}
Com o advento do Método de Newton, acabou surgindo uma família de métodos
similares. E como foi visto, é possível a partir dele, encontrar tanto raízes
de funções, quanto máximos/mínimos, herdando essa características para vários
dos métodos que o derivaram. São estes, Métodos Quasi-Newton e Método do
Gradiente Descendente, que, olhando como ponto de partida o Método de Newton,
fornecem uma grande flexibilidade em como deseja-se utilizar os recursos de
precisão e poder computacional.

Métodos Quasi-Newton se fazem necessários, quando nem sempre se tem acesso ou
recursos suficientes para se calcular a derivada de segunda ordem, ou até mesmo
a de primeira ordem. Já os métodos do Gradiente Descendente, como sugerido pelo
nome, utiliza-se majoritariamente, da derivada de primeira ordem em seu
processo.

Ademais, vejamos alguns outros métodos de otimização:

\subsection{Método do Gradiente Descendente}

Considerando que o Método de Newton encontra o \(min(f(x))\) através de uma
sequência \(\{x_k\}\):

\begin{equation}
    x_{k+1} = x_{k} - \frac {f'(x_{k})}{f''(x_{k})}.
\end{equation}

No qual, pode ser reescrito da seguinte forma:

\begin{equation}
    x_{k+1} = x_{k} -  \frac{1}{f''(x)} * f'(x_{k}).
\end{equation}

E, ressaltando que, sabemos que quem determina a direção da convergência é
\(f'(x)\), não é completamente necessário o uso de \( \frac{1}{f''(x)} \), que
tem como principal papel de controlar o tamanho do `passo dado' na iteração.
De modo que, a maioria dos Métodos Quasi-Newton fazem a substituição
da dada fração por aproximações boas o suficiente. E com isso, levando em
conta $\alpha$ como a representação dessa aproximação, temos:

\begin{equation}
    x_{k+1} = x_{k} -  \alpha * f'(x_{k}).
    \label{newton_lambda}
\end{equation}

Onde \(\alpha\) satisfaz:

\begin{equation}
    f(x_{k} -  \alpha * f'(x_{k})) < f(x_{x}).
    \label{newton_restricao_alpha}
\end{equation}

A partir da equação \ref{newton_lambda}, podemos escolher um \(\alpha\), de
modo que, seja menos custoso encontrá-lo do que calcular a segunda derivada
da função objetivo, ou até, podemos nem calculá-lo, basta considerar
um \(\alpha\) fixo, e tão pequeno que, quando a restrição
\ref{newton_restricao_alpha} não for cumprida, temos uma aproximação boa o
suficiente para o mínimo da função.

Podemos assim, dizer que, esse modelo de resolução é útil e flexível o
suficiente. Tendo isso em mente, e seguindo para o problema de encontrar
o melhor \(\alpha\), donde, já sabemos que sendo um valor pequeno o
suficiente, minimiza a função (mas, não da melhor forma). Já é sabido
que o \(\alpha\) tem como propósito, regular o tamanho do passo dado nas
iterações. Ele pode ser usado em conjunto com outros elementos, afim de
otimizar o processo de otimização.

Normalmente, é usado algum dos seguintes métodos para controlar o tamanho do
passo:

    \begin{itemize}
            \item Um valor fixado para \(\alpha\);
            \item Um método que atualize \(\alpha\) de acordo com alguma
                situação;
            \item Um método que escolha um valor ótimo ou quase ótimo para
                \(\alpha\);
            \item Um elemento que forneça mais informações sobre a função,
                trabalhando em conjunto com o \(\alpha\).
    \end{itemize}


Simplesmente considerar a \(\alpha\) um valor fixo e pequeno, pode funcionar,
mas não seguramente para qualquer situação. Como por exemplo, uma função que
possui `movimentos bruscos', em um escala minúscula. Ou ainda, caso se tenha
considerado um ponto inicial muito distante, de qualquer ótimo, resultando,
em um funcionamento extremamente custoso, do algoritmo.

Atualizar o valor de \(\alpha\), de acordo com a situação do processo iterativo
de otimização, pode ser uma boa opção, quando não se tem tanto poder
computacional. Comumente, pode ser encontrado implementações, que iniciam
com um \(\alpha\) não tão pequeno (isso ajuda a resolver o problema de
iniciar com um ponto longe da solução), mas ao passar das iterações,
reduz-se o seu valor por algum fator. Fator este, que pode ter alguma relação
com a magnitude da derivada, já que, ela pode nos dar uma dica do quão longe
o ótimo está do ponto atual, ou ainda, considerar o fator de redução havendo
uma relação com iteração atual:


Considerando \(\alpha_{0} \in \mathbb{R}^{+}  \), e \(k\) a k-ésima iteração:

\begin{equation}
    \alpha_{k+1} = \frac{\alpha_{k}}{k}.
\end{equation}

Ou ainda:

\begin{equation}
    \alpha_{k+1} = \frac{\alpha_{k}}{2^k} = \frac{\alpha_{0}}{1}.
\end{equation}

Vale a pena ressaltar os métodos mais famosos para tal tipo de atualização,
que também podem ser chamadas de clássicos por serem um ponto inicial, como por
exemplo, o método de Barzilai–Borwein, que pode ser considerado uma atualização
ingenua, porém efetiva e barata de realizar o cálculo. É dada pela seguinte expressão:

\begin{equation}
    \alpha_{k+1} = \frac{\langle \Delta x, \Delta g \rangle}{\langle \Delta g, \Delta g \rangle}.
\end{equation}

Onde, \( \langle \cdot, \cdot \rangle \), significa o produto interno entre
vetores (sendo funções em uma variável apenas, podemos considerar um vetor de
apenas uma entrada), e:

\begin{equation}
    \Delta x = x_k - x_{k-1},
\end{equation}
\begin{equation}
    \Delta g = g_k - g_{k-1}.
\end{equation}


Podemos considerar que \(g_k = f'(x_k) \) nos entrega a noção de direção de
descida, noção essa, que ainda pode ser melhorada, como veremos mais a frente.
Então, por agora, podemos ficar com a ideia de que \(g_k\) é a direção de
descida apenas, independente da forma com que foi obtida.

%TODO: Applied Optimization] Liqun Qi, Kok Lay Teo, Xiao Qi Yang - Optimization and control with applications (2005, Springer) - libgen.lc.pdf, pag 277 do pdf
Tem-se mais alguns métodos semelhantes, como um gerado pelos estudos de
Fletcher e Reeves em 1964, e o método Polak-Ribière em 1997
\ref{AppliedOptimization}.

Quando começamos a observar outras formas de melhorar o valor de \(\alpha\),
acabamos por entrar em uma recursão, pois, daí, começa todo um estudo sobre como
otimizar um parâmetro específico de um otimizador. Os métodos mais famosos que
buscam valores ótimos ou quase ótimos para \(\alpha\), são os métodos
classificados como \textit{line search}. Os quais, normalmente, trabalham
com condições específicas, sobre a otimalidade de \(\alpha\), como as condições
de Wolfe, por exemplo. Tais métodos, utilizam-se dos artifícios citados
anteriormente, já que, são uma peça básica na construção do otimizador,
ou ainda, podem utilizar métodos fora da família dos newtonianos.

Agora, antes de seguirmos para a analise de estatégias para obter um melhor
resultado, se faz necessária uma nova observação, sobre a estrutura básica
dos métodos. Até o momento, viemos considerando apenas a derivada de primeira
ordem como sendo a direção certa a ser tomada. Vamos observar a seguinte
equação:

\begin{equation}
    x_{k+1} = x_{k} - \alpha * \frac{1}{f''(x_k)} * f'(x_k).
\end{equation}

Se tomarmos \(\alpha = 1\), temos o método em sua forma natural. Mas,
podemos procurar um valor para \(\alpha\), que melhore ainda mais a iteração.
E complementando, sabemos sobre as acusações que a derivada de segunda ordem
faz sobre a otimalidade, sendo assim, podemos dizer que a direção de otimização,
na verdade, é dada por:

\begin{equation}
    p_k = \beta(x_k) * f'(x_k).
\end{equation}

Então:

\begin{equation}
    x_{k+1} = x_{k} - \alpha * p_{k}.
\end{equation}


Daí, temos normalmente 3 opções no que se diz respeito ao \(\beta(x_k)\):

\begin{itemize}

    \item A primeira, é considerar \(\beta(x_k) = \frac{1}{f''(x_k)}\), o que
        nos dá o Método de Newton novamente, e o \(\alpha\) não passaria de
        um mero ajuste;

    \item A segunda, é considerar
        \(\beta(x_k) \approx \frac{1}{f''(x_k)}\), o que abre um leque de
        possibilidade no que diz respeito ao cálculo dessa aproximação,
        e, tornando-se assim um método Quasi-Newton. Sendo, esse formato, um dos
        mais populares, de modo que, são aplicados no métodos de otimização
        padrões em bibliotecas cientificas, como \textit{scipy} em Python,
        e \textit{GSL} em C. Sendo um dos mais famosos o método BFGS
        (Broyden-Fletcher-Goldfarb-Shanno).

    \item A terceira, é considerar \(\beta(x_k) \) neutro, de forma que:
        \begin{equation}
            p_k = \beta(x_k) * f'(x_k) = f'(x_k)
        \end{equation}

\end{itemize}

Assim, tendo o Método do Gradiente Descendente, que, como dito anteriormente,
normalmente é resolvido usando a estratégia de \textit{line search}.


\subsection{Simplex}

\hspace{0.8cm}
O método Simplex, pode ser classificado como clássico, por ser um
dos métodos mais famosos. Formulado por George B. Dantzig, fruto de uma
sugestão de outro homem, T. S. Motzkin, que contribuiu para diversas áreas da
matemática.

Os problemas que o método Simplex resolve, fazem parte de uma conjunto de
problemas de Otimização Linear (ou Programação Linear), os quais se restringem
a, apenas, funções lineares. Além disso, tais problemas normalmente acompanham
restrições, sobre as entradas da função a ser otimizada.

Um problema de otimização linear, pode ser resumido em:

\begin{equation}
        Z = c_1x_1 + c_2x_2 + … + c_nx_n
\end{equation}

E tendo restrições também lineares para a função objetivo, como:
\begin{equation}
    \begin{split}
        &   a_{11}x_1 + a_{12}x_2 + … + a_{1n}x_n \leq b_1\\
        &   a_{21}x_1 + a_{22}x_2 + … + a_{2n}x_n \leq b_2\\
        &   ...\\
        &   a_{m1}x_1 + a_{m2}x_2 + … + a_{mn}x_n \leq b_m\\
        &   x_1 \geq 0, x_2 \geq 0, …, x_n \geq 0
    \end{split}
\end{equation}

O tipo de problema que o Simplex resolve, se desenvolve como a seguir:

\begin{equation}
        max \{c^tx | Ax \leq b, x \geq 0\}\\
\end{equation}


A forma de operação desse método é semelhante ao que uma pessoa comumente faria
ao se deparasse com o problema de forma gráfica. O problema, sendo
completamente linear, gera retas, que acabam por formando regiões de
possíveis soluções, e dessas regiões, queremos saber qual a melhor solução.
Para isso, bastaria procurar dentro de tal região, onde o valor da função Z é o
maior possível. Uma vez a região sendo construída por retas, acaba por
ter a característica de ser convexa, como um polígono convexo no plano ou um
poliedro convexo no espaço, o que a acaba por facilitar a busca pelo máximo,
dentro dessa região, uma vez que basta olha os vértices de tal região.

Repara-se, que, o método Simplex não se utiliza de artifícios e ferramentas do
Cálculo, como nos métodos anteriormente apresentados, mas sim, formas
diferentes de analisar o problema, que por certos aspectos é simples. O método
completo é constituído por operações em uma matriz específica (Tableau), que
representa o problema, o qual não é necessário ser apresentado aqui, por se
distanciar da `família' de métodos de otimização que é apresentado neste
documento.



\section{{Programando os Métodos}}

\hspace{0.8cm}

\subsection{Método de Newton}

\hspace{0.8cm}
A forma mais simples e mais útil de implementar o Método de Newton, é na forma
de busca das raízes, que, uma vez implementada, só precisamos por como entrada
a primeira e a segunda derivada da função que desejamos minimizar, já que o
método não precisa saber qual a função de fato. A seguir temos a implementação
na linguagem de programação \textit{Rust}:
\vspace{0.2cm}
\input{./projetos/rust_newton1x1.tex}

Os parâmetros da função são:

    \begin{itemize}
            \item Uma função \(f : \mathbb{R} \rightarrow \mathbb{R}\)
            \item Uma entrada x sendo o chute inicial do ótimo.
    \end{itemize}


A função \textit{derive1x1}, recebe como parâmetro uma função e um ponto,
tendo como retorno, a derivada da função entregue, no ponto especificado.
Restringindo-se à funções do tipo \(f : \mathbb{R} \rightarrow \mathbb{R}\).


\subsection{Método do Gradiente Descendente}

\hspace{0.8cm}
A implementação desse método, exige apenas, que seja definido o cálculo
da derivada da função objetivo, o valor de $\alpha$, um palpite inicial para
o valor de x, e a quantidade de iterações desejada. Também, pode ser
indicado um valor que se refere a diferença dos dois últimos valores
da sequência \{$x_k$\}, podendo assim, efetuar a parada da execução do
método. A seguir, temos a implementação na linguagem de programação
\textit{C++}:

\vspace{0.2cm}
\input{./projetos/cpp_gradient1x1.tex}




\textcolor[rgb]{1,0,0}{\section{{O Método de Newton para Várias Variáveis}}}
