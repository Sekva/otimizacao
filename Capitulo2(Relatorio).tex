%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Relatório Final - Projeto de Pesquisa
% Métodos de Otimização
% Baltz & Machado
% Capítulo 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{\Large{Métodos Clássicos de Otimização}}\label{chp:2}


\section{{O Método de Newton}}


\subsection{Entendendo o Método}

%TODO: Falar de funções bem definidas

\hspace{0.8cm}
O Método de Newton, foi desenvolvido com o objetivo de encontrar estimativas
para as raízes de uma função. De modo que, a execução do método é feita de
forma iterativa, repetindo sempre o mesmo processo, atualizando o mesmo valor.

Este método faz uso do recurso de derivação, existindo, uma relação muito
forte com o ângulo da reta tangente ao ponto, na função. Ademais, é
importante ressaltar, que é necessário um palpite inicial, que represente
o valor de \textit{x}, no qual, partindo desse valor, será buscado a raiz.
E com isso, vamos entender como o dado método funciona.

Partindo do princípio do método, o objetivo, será utilizar a reta tangente a um
ponto, para gerar valores cada vez mais próximos da raiz daquela função. De
modo que, será analisado a interseção da reta tangente com o eixo das
abscissas. E sendo, a diferença do valor x da entrada da função com o valor da
fração entre a função e sua derivada no mesmo ponto, o novo valor de entrada na
função, construindo assim várias iterações, gerando valores cada vez mais
próximos da raiz. Como será visto, a seguir:

Já sabido que a equação da reta é dada como:

\begin{equation}
    (y - y_0) = m(x - x_0).
\end{equation}

E levando em conta que temos como objetivo encontrar $x$, que é um ponto
sobreposto no eixo x, podemos considerar $y=0$, logo:

\begin{equation}
    -y_0=m(x-x_0).
\end{equation}

Com isso, sabemos que $y_0$ é a imagem da função $f(x_0)$, e $m$ representa o
ângulo da reta tangente ao ponto $x_0$, ou seja: $m=f'(x_0)$. Desenvolvendo
essa equação, temos:

\begin{equation}
    -f(x_0) = f'(x_0)(x-x_0),
\end{equation}

\begin{equation}
    -f(x_0) = f'(x_0)x - f'(x_0)x_0,
\end{equation}

\begin{equation}
    0 = f'(x_0)x - f'(x_0)x_0+f(x_0),
\end{equation}

\begin{equation}
    0 = x - x_0 + \frac{f(x_0)}{f'(x_0)},
\end{equation}

\begin{equation}
    x = x_0 - \frac {f(x_0)}{f'(x_0)}.
\end{equation}\\

E com isso, exemplificando em um gráfico, temos que, sendo $f(x)=-x^2+2x$, o
palpite inicial $x_0=1.5$, $P1$ sendo o ponto que representa $x_0$ aplicado
a função $f$ e $x1$ a interseção da reta tangente à $P1$ com o eixo x.

\begin{figure}[ht]
    \includegraphics[width=0.55\textwidth]
      {src/MetodoNewton_grafico_1.png}
    \centering
    \caption{
      Primeira iteração do Método de Newton.
     }
    \label{MetodoNewton_grafico_1}
\end{figure}


E a partir do dado gráfico, agora podemos entender melhor como a iteração
funcionará, pois, o valor gerado, $x_1$, será aplicado no mesmo método. E com
isso, podemos construir a seguinte equação:

\begin{equation}
    x_{k+1} = x_{k} - \frac {f(x_{k})}{f'(x_{k})}.
    \label{newton_primeiraDeriv}
\end{equation}

Desse modo, gera-se uma sequência $\{x_k\}$, donde, esta, converge para a
raiz da função. E nesse sentido, vejamos a próxima iteração (Figura
\ref{MetodoNewton_grafico_2}) do exemplo mostrado na Figura
\ref{MetodoNewton_grafico_1}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.55\textwidth]
      {src/MetodoNewton_grafico_2.png}
    \caption{
      Segunda iteração do Método de Newton.
    }
    \label{MetodoNewton_grafico_2}
\end{figure}

E assim, podemos notar a aproximação de $x_k$ para a raiz de $f$, observando o
ponto $x_2$.

Ademais, é válido ressaltar que o denominador da equação
\ref{newton_primeiraDeriv} tem que ser diferente de 0 (ou seja, a reta tangante
num ponto $P$ não pode ser paralela ao eixo x). No entanto, caso contrário,
isso significa que a dada função não possui raiz na proximidade daquele ponto.

\subsection{Encontrando Mínimos}

E é dessa maneira que, agora, podemos utilizar este método para encontrar
mínimos de uma função. Vimos que, o Método de Newton calcula raízes, e
desse modo, vinculando o que foi estudado no Capítulo 1, sabemos que, os
mínimos de uma função podem ser representados como raízes de sua derivada.

%TODO: Falar mais/melhor sobre a sequencia {x_k} (tendencia ao 0 da função)

Então, dado que as raízes de $f(x)$ podem ser geradas a partir da equação
\ref{newton_primeiraDeriv}, temos que: considerando $g(x)$ uma função duas vezes
derivável, e tendo como objetivo encontrar seus pontos de mínimo, pode-se
utilizar o Método de Newton para resolver tal problema da seguinte forma:

\begin{equation}
    x_{k+1} = x_{k} - \frac {g'(x_{k})}{g''(x_{k})}.
\end{equation}

Encontrando então as raízes aproximadas de sua derivada, e considerando
estas como  $x^*$, temos então que:

\begin{equation}
    g'(x^*) = 0.
\end{equation}

O método é simples, entrega muitas vezes ótimos locais próximos ao ponto
inicial, mas tem seu destaque, que é ser, facilmente computável.

Problemas de maximização podem ser vistos sob o seguinte olhar:

\begin{equation}
    max(f(x)) = min(-1 * f(x))
\end{equation}

Que com isto podem ser otimizados pelo Método de Newton também.

O movimento de \(x_k\) dentro da sequência, é determinado pela relação das
quantidades e propriedades, que tanto a primeira quanto a segunda derivada
oferecem. As quantidades, determinam a velocidade do movimento, e os sinais,
indicam a direção do movimento. De certa forma, podemos interpretar o movimento
da sequência \(\{x_k\}\) como instantes do movimento de uma bola numa ladeira,
que no começo de sua descida é acelerada, e, conforme chega ao plano no fim da
ladeira, começa a reduzir sua velocidade, até supostamente chegar no ponto mais
baixo.


\section{{Outros Métodos}}

Com o advento do Método de Newton, acabou surgindo uma família de métodos
similares. E como foi visto, é possível a partir dele, encontrar tanto raízes
de funções, quanto máximos/mínimos, herdando essa características para vários
dos métodos que o derivaram. São estes, Métodos Quasi-Newton e Método do
Gradiente Descendente, que, olhando como ponto de partida o Método de Newton, 
fornecem uma grande flexibilidade em como deseja-se utilizar os recursos de
precisão e poder computacional.

Métodos Quasi-Newton se fazem necessários quando nem sempre se tem acesso ou
recursos suficientes para se calcular a derivada de segunda ordem, ou até mesmo
a de primeira ordem. Já os métodos do Gradiente Descendente, como sugerido pelo
nome, utiliza-se majoritariamente da derivada de primeira ordem em seu processo.

Ademais, vejamos alguns outros métodos de otimização:

\subsection{Método do Gradiente Descendente}

Considerando que o Método de Newton encontra o \(min(f(x))\) através de uma
sequência \(\{x_k\}\):

\begin{equation}
    x_{k+1} = x_{k} - \frac {f'(x_{k})}{f''(x_{k})}.
\end{equation}

No qual, pode ser reescrito da seguinte forma:

\begin{equation}
    x_{k+1} = x_{k} -  \frac{1}{f''(x)} * f'(x_{k}).
\end{equation}

E, ressaltando que, sabemos que quem determina a direção da convergência é
\(f'(x)\), não é completamente necessário o uso de \( \frac{1}{f''(x)} \), que
tem como principal papel de controlar o tamanho do `passo dado' na iteração.
De modo que, a maioria dos Métodos Quasi-Newton fazem a substituição
da dada fração por aproximações boas o suficiente. E com isso, levando em
conta $\alpha$ como a representação dessa aproximação, temos:

\begin{equation}
    x_{k+1} = x_{k} -  \alpha * f'(x_{k}).
    \label{newton_lambda}
\end{equation}

Onde \(\alpha\) satisfaz:

\begin{equation}
    f(x_{k} -  \alpha * f'(x_{k})) < f(x_{x}).
    \label{newton_restricao_alpha}
\end{equation}

A partir da equação \ref{newton_lambda}, podemos escolher um \(\alpha\), de
modo que, seja menos custoso encontrá-lo do que calcular a segunda derivada
da função objetivo, ou até, podemos nem calculá-lo, basta considerar
um \(\alpha\) fixo, e tão pequeno que, quando a restrição
\ref{newton_restricao_alpha} não for cumprida, temos uma aproximação boa o
suficiente para o minimo da função.

Podemos assim dizer que esse modelo de resolução é útil e flexível o suficiente.
Tendo isso em mente, podemos seguir para o problema de encontrar o melhor
\(\alpha\), que já sabemos que sendo pequeno o suficiente minimiza a função, mas
talvez não da melhor forma possível. Sabemos que o \(\alpha\) tem que regular o
tamanho do passo. Ele pode ser usado em conjunto com outros elementos afim de
otimizar o processo de otimização.

Normalmente se é usado algum dos seguintes métodos para controlar o tamanho do
passo:

    \begin{itemize}
            \item Um valor fixado para \(\alpha\);
            \item Um método que atualize \(\alpha\) de acordo com alguma situação;
            \item Um método que escolha um valor ótimo ou quase ótimo para \(\alpha\);
            \item Um elemento que forneça mais informações sobre a função trabalhando em conjunto com o \(\alpha\).
    \end{itemize}


Simplesmente considerar um \(\alpha\) um valor fixo e pequeno pode funcionar,
mas não seguramente para qualquer situação, como por exemplo uma função que
possui "movimentos bruscos" em um escala minuscula, ou ainda, caso se tenha
considerado um ponto inicial muito distante de qualquer ótimo que seja, o que
faz com que o algoritmo seja absurdamente custoso.

Atualizar o valor de \(\alpha\) de acordo com a situação do processo iterativo
de otimização pode ser uma boa opção quando não se tem tanto pode computacional.
Comumente pode ser encontrado implementações que iniciam com um \(\alpha\) não
tão pequeno (isso ajuda a resolver o problema de iniciar com um ponto longe da 
solução), mas ao passar das iterações, reduzir o seu valor por algum fator.
Fator este que pode ser alguma relação com a magnitude da derivada, já que ela
pode nos dar uma dica do quão longe o ótimo está do ponto atual, ou ainda
considerar o fator de redução como a relação com a iteração atual:


Considerando \(\alpha_{0} \in \mathbb{R}^{+}  \), e \(k\) a k-ésima iteração:

\begin{equation}
    \alpha_{k+1} = \frac{\alpha_{k}}{k}
\end{equation}

Ou ainda:

\begin{equation}
    \alpha_{k+1} = \frac{\alpha_{k}}{2} = \frac{\alpha_{0}}{2^k} 
\end{equation}


Quando começamos a observar outras formas de melhorar o valor de \(\alpha\),
acabamos por entrar em uma recursão, pois dai começa todo um estudo sobre como
otimizar um parâmetro específico de um otimizador. Os métodos mais famosos que
buscam valores ótimos ou quase ótimos para \(\alpha\) são os métodos
\textit{line search}. Os quais normalmente se trabalham com condições específicas
sobre a otimalidade de \(\alpha\), como as condições de Wolfe por exemplo. Tais
métodos utilizam-se dos artifícios citados anteriormente, já que são uma peça
básica na construção do otimizador, ou ainda podem se utilizar de métodos fora
dessa família de métodos newtonianos.

Agora, antes de seguirmos para a analise de algum elemento de ajuda no valor, se
faz necessária uma nova observação sobre a estrutura básica dos métodos. Até o
momento viemos considerando apenas a derivada de primeira ordem como sendo a
direção certa a ser tomada. Vamos tomar a seguinte equação:

\begin{equation}
    x_{k+1} = x_{k} - \alpha * \frac{1}{f''(x_k)} * f'(x_k)
\end{equation}

Se tomarmos \(\alpha = 1\) temos o método em sua forma natural. Mas ainda
podemos procurar um valor para \(\alpha\) que melhore ainda mais a iteração.
E mais, sabemos sobre as acusações que as derivadas de segunda ordem fazem,
sobre a otimalidade, sendo assim podemos dizer que a direção de otimização,
na verdade, é dada por:

\begin{equation}
    p_k = \beta(x_k) * f'(x_k)
\end{equation}

Então:

\begin{equation}
    x_{k+1} = x_{k} - \alpha * p_{k}
\end{equation}


Dai temos normalmente 3 opções no que se diz respeito ao \(\beta(x_k)\):

A primeira é considerar \(\beta(x_k) \frac{1}{f''(x_k)}\), o que nos dá
o método de Newton, novamente, e o \(\alpha\) não passaria de um mero ajuste.

A segunda opção é considerar \(\beta(x_k) \approx \frac{1}{f''(x_k)}\), o que
abre um leque de possibilidade no que diz respeito ao calculo dessa aproximação,
e, tornando-se assim um método Quasi-Newton. Esse formato é um dos mais
populares, sendo os métodos de otimização padrões em bibliotecas cientificas,
como scipy em Python, e GSL em C. Sendo um dos mais famosos o método BFGS
(Broyden-Fletcher-Goldfarb-Shanno).


A terceira opção é considerar \(\beta(x_k) \) neutro, de forma que:
\begin{equation}
    p_k = \beta(x_k) * f'(x_k) = f'(x_k)
\end{equation}

Assim tendo um método do Gradiente Descendente, que como dito anteriormente,
normalmente é resolvido por um método de \textit{line search}.






\subsection{Simplex}

\hspace{0.8cm}
O método Simplex, pode ser classificado como clássico, por ser um
dos métodos mais famosos. Formulado por George B. Dantzig, fruto de uma
sugestão de outro homem, T. S. Motzkin, que contribuiu para diversas áreas da
matemática.

Os problemas que o método Simplex resolve, fazem parte de uma conjunto de
problemas de Otimização Linear (ou Programação Linear), os quais se restringem
a, apenas, funções lineares. Além disso, tais problemas normalmente acompanham
restrições, sobre as entradas da função a ser otimizada.

Um problema de otimização linear, pode ser resumido em:

\begin{equation}
        Z = c_1x_1 + c_2x_2 + … + c_nx_n
\end{equation}

E tendo restrições também lineares para a função objetivo, como:
\begin{equation}
    \begin{split}
        &   a_{11}x_1 + a_{12}x_2 + … + a_{1n}x_n \leq b_1\\
        &   a_{21}x_1 + a_{22}x_2 + … + a_{2n}x_n \leq b_2\\
        &   ...\\
        &   a_{m1}x_1 + a_{m2}x_2 + … + a_{mn}x_n \leq b_m\\
        &   x_1 \geq 0, x_2 \geq 0, …, x_n \geq 0
    \end{split}
\end{equation}

O tipo de problema que o Simplex resolve, se desenvolve como a seguir:

\begin{equation}
        max \{c^tx | Ax \leq b, x \geq 0\}\\
\end{equation}


A forma de operação desse método é semelhante ao que uma pessoa comumente faria
ao se deparasse com o problema de forma gráfica. O problema, sendo
completamente linear, gera retas, que acabam por formando regiões de
possíveis soluções, e dessas regiões, queremos saber qual a melhor solução.
Para isso, bastaria procurar dentro de tal região, onde o valor da função Z é o
maior possível. Uma vez a região sendo construída por retas, acaba por
ter a característica de ser convexa, como um polígono convexo no plano ou um
poliedro convexo no espaço, o que a acaba por facilitar a busca pelo máximo,
dentro dessa região, uma vez que basta olha os vértices de tal região.

Repara-se, que, o método Simplex não se utiliza de artifícios e ferramentas do
Cálculo, como nos métodos anteriormente apresentados, mas sim, formas
diferentes de analisar o problema, que por certos aspectos é simples. O método
completo é constituído por operações em uma matriz específica (Tableau), que
representa o problema, o qual não é necessário ser apresentado aqui, por se
distanciar da `família' de métodos de otimização que é apresentado neste
documento.



\section{{Programando os Métodos}}

\hspace{0.8cm}

\subsection{Método de Newton}

\hspace{0.8cm}
A forma mais simples e mais útil de implementar o Método de Newton, é na forma
de busca das raízes, que, uma vez implementada, só precisamos por como entrada
a primeira e a segunda derivada da função que desejamos minimizar, já que o
método não precisa saber qual a função de fato. A seguir temos a implementação
na linguagem de programação \textit{Rust}:
\vspace{0.2cm}
\input{./projetos/rust_newton1x1.tex}

Os parâmetros da função são:

    \begin{itemize}
            \item Uma função \(f : \mathbb{R} \rightarrow \mathbb{R}\)
            \item Uma entrada x sendo o chute inicial do ótimo.
    \end{itemize}


A função \textit{derive1x1}, recebe como parâmetro uma função e um ponto,
tendo como retorno, a derivada da função entregue, no ponto especificado.
Restringindo-se à funções do tipo \(f : \mathbb{R} \rightarrow \mathbb{R}\).


\subsection{Método do Gradiente Descendente}

\hspace{0.8cm}
A implementação desse método, exige apenas, que seja definido o cálculo
da derivada da função objetivo, o valor de $\alpha$, um palpite inicial para
o valor de x, e a quantidade de iterações desejada. Também, pode ser
indicado um valor que se refere a diferença dos dois últimos valores
da sequência \{$x_k$\}, podendo assim, efetuar a parada da execução do
método. A seguir, temos a implementação na linguagem de programação
\textit{C++}:

\vspace{0.2cm}
\input{./projetos/cpp_gradient1x1.tex}




textcolor[rgb]{1,0,0}{\section{{O Método de Newton para Várias Variáveis}}}
